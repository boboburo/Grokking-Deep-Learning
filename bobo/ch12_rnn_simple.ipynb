{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T18:23:06.336574Z",
     "start_time": "2020-12-29T18:23:06.159573Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T18:23:06.356530Z",
     "start_time": "2020-12-29T18:23:06.352833Z"
    }
   },
   "outputs": [],
   "source": [
    "def softmax(x_):\n",
    "    x = np.atleast_2d(x_) #turns it from 1d vector to 2d\n",
    "    temp = np.exp(x)\n",
    "    return temp / np.sum(temp, axis =1, keepdims = True) #axis = 1 is sum the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T18:23:11.603934Z",
     "start_time": "2020-12-29T18:23:11.598005Z"
    }
   },
   "outputs": [],
   "source": [
    "word_vects = {}\n",
    "word_vect_template  = np.array([[0.,0.,0.]])\n",
    "\n",
    "word_list = ['yankees','bears','braves','red','sox','lose','defeat','beat','tie']\n",
    "\n",
    "for w in word_list:\n",
    "    word_vects[w] = word_vect_template.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T18:23:12.529507Z",
     "start_time": "2020-12-29T18:23:12.519636Z"
    }
   },
   "outputs": [],
   "source": [
    "sent2output = np.random.rand(3, len(word_vects)) #[3,9]\n",
    "identity = np.eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T18:25:07.429894Z",
     "start_time": "2020-12-29T18:25:07.384332Z"
    }
   },
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "y = np.array([1,0,0,0,0,0,0,0,0])\n",
    "\n",
    "for i in range(100):\n",
    "    \n",
    "    layer_0 = word_vects['red']\n",
    "    layer_1 = layer_0.dot(identity) + word_vects['sox']\n",
    "    layer_2 = layer_1.dot(identity) + word_vects['defeat']\n",
    "    \n",
    "    pred = softmax(layer_2.dot(sent2output))\n",
    "    \n",
    "    pred_delta = pred - y\n",
    "\n",
    "    layer_2_delta = pred_delta.dot(sent2output.T)\n",
    "    defeat_delta = layer_2_delta*1\n",
    "\n",
    "    layer_1_delta = layer_2_delta.dot(identity.T)\n",
    "    sox_delta = layer_1_delta*1\n",
    "\n",
    "    layer_0_delta = layer_1_delta.dot(identity.T)\n",
    "\n",
    "    word_vects['red'] -= layer_0_delta*alpha\n",
    "    word_vects['sox'] -= sox_delta*alpha\n",
    "    word_vects['defeat'] -= defeat_delta*alpha\n",
    "\n",
    "    identity -= np.outer(layer_1_delta, layer_0) * alpha\n",
    "    identity -= np.outer(layer_2_delta, layer_1) * alpha\n",
    "\n",
    "    sent2output -= np.outer(layer_2, pred_delta) * alpha\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T18:25:08.732124Z",
     "start_time": "2020-12-29T18:25:08.722590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred:[[9.98823603e-01 4.20314950e-04 1.93267980e-05 1.01757538e-05\n",
      "  2.07021787e-04 2.67410218e-05 1.72270358e-05 1.73633972e-05\n",
      "  4.58226611e-04]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Pred:{pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'yankees': array([[0., 0., 0.]]),\n",
       " 'bears': array([[0., 0., 0.]]),\n",
       " 'braves': array([[0., 0., 0.]]),\n",
       " 'red': array([[ 0.26963643,  0.09524509, -0.95404756]]),\n",
       " 'sox': array([[ 0.21187229,  0.07510011, -0.748406  ]]),\n",
       " 'lose': array([[0., 0., 0.]]),\n",
       " 'defeat': array([[ 0.17292935,  0.06149844, -0.61046878]]),\n",
       " 'beat': array([[0., 0., 0.]]),\n",
       " 'tie': array([[0., 0., 0.]])}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.0654789 ,  0.02360239, -0.22343479],\n",
       "       [ 0.02289487,  1.00825382, -0.07813104],\n",
       "       [-0.24134894, -0.08691185,  1.82438203]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.72811039,  0.64169343, -0.01999513,  0.28553359,  0.09586716,\n",
       "         0.07018994,  0.1667832 ,  0.32603584,  0.31325793],\n",
       "       [ 0.65213613,  0.39069632,  0.67782664,  0.19826064,  0.85961047,\n",
       "         0.01925624,  0.66330383,  0.41012379,  0.5284361 ],\n",
       "       [-0.90985744,  0.46482497,  0.86804662,  1.0243646 ,  0.48545377,\n",
       "         0.76653727,  0.94154838,  0.95992813,  0.36843507]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-26T14:34:34.594537Z",
     "start_time": "2020-12-26T14:34:34.589755Z"
    }
   },
   "source": [
    "# What is normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-26T15:13:00.683934Z",
     "start_time": "2020-12-26T15:13:00.680551Z"
    }
   },
   "outputs": [],
   "source": [
    "w01 = np.random.rand(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-26T15:13:00.857502Z",
     "start_time": "2020-12-26T15:13:00.852057Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.95219721e-04, 6.87015833e-04, 8.01257264e-04, 6.06198898e-02],\n",
       "       [7.39648073e-01, 2.90338916e-01, 3.05612140e-01, 7.09016024e-01],\n",
       "       [1.54190122e-02, 7.79435266e-02, 3.43113924e-01, 9.40115915e-01]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(w01 * w01) #element wise multiplication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-26T15:13:01.027526Z",
     "start_time": "2020-12-26T15:13:01.022205Z"
    }
   },
   "outputs": [],
   "source": [
    "norms = np.sum(w01*w01, axis = 1) #[3,1]\n",
    "norms.resize(norms.shape[0],1)\n",
    "\n",
    "normed_weights = w01 * norms #ew multiplation/scaled by the column sum ; give you 0-1 for each column "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN with dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,random,math\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "f = open('../original/tasksv11/en/qa1_single-supporting-fact_train.txt','r')\n",
    "raw = f.readlines()\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mary', 'moved', 'to', 'the', 'bathroom']\n",
      "['john', 'went', 'to', 'the', 'hallway']\n",
      "['where', 'is', 'mary', 'bathroom']\n",
      "['daniel', 'went', 'back', 'to', 'the', 'hallway']\n",
      "['sandra', 'moved', 'to', 'the', 'garden']\n"
     ]
    }
   ],
   "source": [
    "for line in raw[0:5]:\n",
    "    print(line.lower().\n",
    "          replace(\"\\n\",\"\").\n",
    "          replace(\"\\t\",\"\").\n",
    "          replace(\".\",\"\").\n",
    "          replace(\"?\",\"\").\n",
    "          replace(\"1\",\"\").split(\" \")[1:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-26T15:15:26.704264Z",
     "start_time": "2020-12-26T15:15:26.700088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['mary', 'moved', 'to', 'the', 'bathroom'], ['john', 'went', 'to', 'the', 'hallway'], ['where', 'is', 'mary', 'bathroom'], ['daniel', 'went', 'back', 'to', 'the', 'hallway'], ['sandra', 'moved', 'to', 'the', 'garden']]\n"
     ]
    }
   ],
   "source": [
    "tokens = list()\n",
    "for line in raw[0:5]:\n",
    "    tokens.append(line.lower().\n",
    "          replace(\"\\n\",\"\").\n",
    "          replace(\"\\t\",\"\").\n",
    "          replace(\".\",\"\").\n",
    "          replace(\"?\",\"\").\n",
    "          replace(\"1\",\"\").split(\" \")[1:]\n",
    "                 )\n",
    "    \n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-26T15:17:04.045342Z",
     "start_time": "2020-12-26T15:17:04.035229Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "vocab = set()\n",
    "wrdcnt = 0\n",
    "for sent in tokens:\n",
    "    for word in sent:\n",
    "        vocab.add(word)\n",
    "        wrdcnt += 1\n",
    "\n",
    "vocab = list(vocab)\n",
    " \n",
    "print(len(vocab))\n",
    "print(wrdcnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-26T15:23:26.501751Z",
     "start_time": "2020-12-26T15:23:26.495725Z"
    }
   },
   "outputs": [],
   "source": [
    "word2index = {}\n",
    "for i,word in enumerate(vocab):\n",
    "    word2index[word] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-26T15:24:37.857651Z",
     "start_time": "2020-12-26T15:24:37.848340Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bathroom',\n",
       " 'where',\n",
       " 'to',\n",
       " 'mary',\n",
       " 'moved',\n",
       " 'back',\n",
       " 'went',\n",
       " 'daniel',\n",
       " 'is',\n",
       " 'sandra',\n",
       " 'hallway',\n",
       " 'the',\n",
       " 'garden',\n",
       " 'john']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-26T15:19:14.427085Z",
     "start_time": "2020-12-26T15:19:14.422016Z"
    }
   },
   "outputs": [],
   "source": [
    "def words2indices(sentence):\n",
    "    idx = list()\n",
    "    for word in sentence:\n",
    "        idx.append(word2index[word])\n",
    "    return idx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-26T15:21:39.038889Z",
     "start_time": "2020-12-26T15:21:39.032241Z"
    }
   },
   "outputs": [],
   "source": [
    "embed_size = 10\n",
    "\n",
    "embed = (np.random.rand(len(vocab), embed_size) - 0.5)*0.1\n",
    "recurrent = np.eye(embed_size)\n",
    "start = np.zeros(embed_size)\n",
    "decoder = (np.random.rand(embed_size, len(vocab)) - 0.5) * 0.1\n",
    "one_hot = np.eye(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-27T16:29:19.098044Z",
     "start_time": "2020-12-27T16:29:19.075666Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(sent):\n",
    "    \n",
    "    layers = list()\n",
    "    layer = {}\n",
    "    layer['hidden'] = start\n",
    "    layers.append(layer)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    # forward propagate\n",
    "    preds = list()\n",
    "    for target_i in range(len(sent)):\n",
    "\n",
    "        layer = {}\n",
    "\n",
    "        # try to predict the next term\n",
    "        layer['pred'] = softmax(layers[-1]['hidden'].dot(decoder)) #[10,][10,19] = [1,19]\n",
    "\n",
    "        loss += -np.log(layer['pred'][sent[target_i]]) #will be zero if 1\n",
    "\n",
    "        # generate the next hidden state\n",
    "        layer['hidden'] = layers[-1]['hidden'].dot(recurrent) + embed[sent[target_i]] #[10,1][10,10] + [1,10]\n",
    "        layers.append(layer)\n",
    "        \n",
    "    return layers, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-27T16:29:19.297835Z",
     "start_time": "2020-12-27T16:29:19.282617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-bac7b9d31364>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwords2indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Sentence less the first word, with an interator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#returns multiple pred layers for each word [19,]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# back propagate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-73-3113df0b4277>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(sent)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hidden'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#[10,][10,19] = [1,19]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#will be zero if 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# generate the next hidden state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "# forward\n",
    "for iter in range(8):\n",
    "    alpha = 0.001\n",
    "    sent = words2indices(tokens[iter%len(tokens)][1:]) #Sentence less the first word, with an interator \n",
    "    \n",
    "    \n",
    "    \n",
    "    layers,loss = predict(sent) #returns multiple pred layers for each word [19,]\n",
    "\n",
    "    # back propagate\n",
    "    for layer_idx in reversed(range(len(layers))):\n",
    "        print(layer_idx)\n",
    "        layer = layers[layer_idx]\n",
    "        target = sent[layer_idx-1] #because the sent is reduced by 1 in length and there is a start layer added when \n",
    "        #passed to predict(sent)\n",
    "\n",
    "        if(layer_idx > 0):  # if not the first layer\n",
    "            layer['output_delta'] = layer['pred'] - one_hot[target] #takes a particular row away [19,]\n",
    "            new_hidden_delta = layer['output_delta'].dot(decoder.transpose()) #[19,][10,19] = [10,]\n",
    "            \n",
    "            # if the last layer - don't pull from a later one becasue it doesn't exist\n",
    "            if(layer_idx == len(layers)-1):\n",
    "                layer['hidden_delta'] = new_hidden_delta\n",
    "            else:\n",
    "                layer['hidden_delta'] = new_hidden_delta + layers[layer_idx+1]['hidden_delta'].dot(recurrent.transpose())\n",
    "        else: # if the first layer\n",
    "            layer['hidden_delta'] = layers[layer_idx+1]['hidden_delta'].dot(recurrent.transpose())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
