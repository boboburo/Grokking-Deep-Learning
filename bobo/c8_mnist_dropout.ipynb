{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intuition\n",
    "\n",
    "Randomly set neurons in the network to 0 (and the neurons detlas for back prop). Like the clay analogy , imagine now the clay is sticky rocks the size of dimes. Each only captures partial impressions of the shape won't latch on to insignificant details - averaging of the shape. \n",
    "\n",
    "100 neural networks, will find the same broad signial, but different parts of the  noise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "dropout_mask = np.random.randint(2,size = 4) #50% random 1/0, randint(how many randoms, size )\n",
    "dropout_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout_mask = np.random.randint(2,size = (2,8)) #50% random 1/0\n",
    "dropout_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl = np.array([[2,2,2],\n",
    "              [2,2,2],\n",
    "              [2,2,2],\n",
    "              [2,2,2]])\n",
    "\n",
    "w01 = 2*np.random.random((3,3)) - 1\n",
    "layer_1 = np.dot(sl, w01)\n",
    "\n",
    "dropout_mask = np.random.randint(2, size = layer_1.shape)\n",
    "dropout_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49234719, -2.24365296,  0.01728756],\n",
       "       [ 0.49234719, -2.24365296,  0.01728756],\n",
       "       [ 0.49234719, -2.24365296,  0.01728756],\n",
       "       [ 0.49234719, -2.24365296,  0.01728756]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (4,3) and (4,3) not aligned: 3 (dim 1) != 4 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-a22d7b8d6a73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (4,3) and (4,3) not aligned: 3 (dim 1) != 4 (dim 0)"
     ]
    }
   ],
   "source": [
    "np.dot(layer_1, dropout_mask) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.98469438, -0.        ,  0.        ],\n",
       "       [ 0.98469438, -4.48730592,  0.        ],\n",
       "       [ 0.        , -0.        ,  0.03457512],\n",
       "       [ 0.        , -4.48730592,  0.        ]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_1 *= dropout_mask * 2\n",
    "layer_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:(60000, 28, 28), y_train:(60000,)\n",
      "x_test:(10000, 28, 28), y_test:(10000,)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(f\"x_train:{x_train.shape}, y_train:{y_train.shape}\") #60k\n",
    "print(f\"x_test:{x_test.shape}, y_test:{y_test.shape}\") #10k\n",
    "\n",
    "def one_hot_labels(digit_labels):\n",
    "    \n",
    "    one_hot_labels = np.zeros((len(digit_labels),10))\n",
    "\n",
    "    for i,l in enumerate(digit_labels):\n",
    "        one_hot_labels[i][l] = 1\n",
    "    \n",
    "    return(one_hot_labels)\n",
    "\n",
    "relu = lambda x:(x>=0) * x # returns x if x > 0, return 0 otherwise\n",
    "relu2deriv = lambda x: x>=0 # returns 1 for input > 0, return 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_images = x_train[0:1000].reshape(1000, 28*28)/255\n",
    "trn_labels = one_hot_labels(y_train[0:1000])\n",
    "\n",
    "tst_images = x_test.reshape(len(x_test), 28*28)/255\n",
    "tst_labels = one_hot_labels(y_test)\n",
    "\n",
    "np.random.seed(1)\n",
    "alpha, iterations, hidden_size, pixels_per_image, num_labels = (0.005, 350, 40, 784, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 5.01 µs\n",
      "Iteration:0, Trn-Err:.0.885, Tst-Err:.0.718, Trn-Acc:0.289, Tst-Acc:0.542.\n",
      "Iteration:50, Trn-Err:.0.463, Tst-Err:.0.431, Trn-Acc:0.742, Tst-Acc:0.815.\n",
      "Iteration:100, Trn-Err:.0.453, Tst-Err:.0.433, Trn-Acc:0.769, Tst-Acc:0.804.\n",
      "Iteration:150, Trn-Err:.0.458, Tst-Err:.0.447, Trn-Acc:0.783, Tst-Acc:0.792.\n",
      "Iteration:200, Trn-Err:.0.443, Tst-Err:.0.437, Trn-Acc:0.796, Tst-Acc:0.803.\n",
      "Iteration:250, Trn-Err:.0.433, Tst-Err:.0.421, Trn-Acc:0.789, Tst-Acc:0.805.\n",
      "Iteration:300, Trn-Err:.0.408, Tst-Err:.0.434, Trn-Acc:0.804, Tst-Acc:0.795.\n",
      "Iteration:349, Trn-Err:.0.419, Tst-Err:.0.421, Trn-Acc:0.802, Tst-Acc:0.808.\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "weights_0_1 = 0.2*np.random.random((pixels_per_image,hidden_size)) - 0.1\n",
    "weights_1_2 = 0.2*np.random.random((hidden_size,num_labels)) - 0.1\n",
    "\n",
    "for j in range(iterations):\n",
    "    error, correct_cnt = (0.0, 0)\n",
    "    \n",
    "    for i in range(len(trn_images)):\n",
    "        layer_0 = trn_images[i:i+1]\n",
    "        layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "        \n",
    "        ###########################################\n",
    "        dropout_mask = np.random.randint(2, size = layer_1.shape)\n",
    "        layer_1 *= dropout_mask * 2 #amplification\n",
    "        ############################################\n",
    "        \n",
    "        layer_2 = np.dot(layer_1,weights_1_2)\n",
    "\n",
    "        error += np.sum((trn_labels[i:i+1] - layer_2) ** 2)\n",
    "        correct_cnt += int(np.argmax(layer_2) == \\\n",
    "                                        np.argmax(trn_labels[i:i+1]))\n",
    "\n",
    "        #spread the delta\n",
    "        layer_2_delta = (trn_labels[i:i+1] - layer_2)\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T)* relu2deriv(layer_1)\n",
    "        \n",
    "        ##############################\n",
    "        layer_1_delta *= dropout_mask\n",
    "        ##############################\n",
    "        \n",
    "        \n",
    "        #input* delta\n",
    "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
    "        weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
    "        \n",
    "    #print(f\"Iteration:{j}, Trn-Err:.{error/len(trn_images):.3f},Trn-Acc:{correct_cnt/float(len(trn_images)):.3f}\", end = '\\r')\n",
    "    \n",
    "    \n",
    "    if(j % 50 == 0 or j == iterations-1):\n",
    "        tst_error, tst_correct_cnt = (0.0, 0)\n",
    "\n",
    "        for i in range(len(tst_images)):\n",
    "\n",
    "            layer_0 = tst_images[i:i+1]\n",
    "            layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "            layer_2 = np.dot(layer_1,weights_1_2)\n",
    "\n",
    "            tst_error += np.sum((tst_labels[i:i+1] - layer_2) ** 2)\n",
    "            tst_correct_cnt += int(np.argmax(layer_2) == np.argmax(tst_labels[i:i+1]))\n",
    "            \n",
    "        msg = (\n",
    "            f\"Iteration:{j}, \"\n",
    "            f\"Trn-Err:.{error/len(trn_images):.3f}, \"\n",
    "            f\"Tst-Err:.{tst_error/len(tst_images):.3f}, \"\n",
    "            f\"Trn-Acc:{correct_cnt/float(len(trn_images)):.3f}, \"\n",
    "            f\"Tst-Acc:{tst_correct_cnt/float(len(tst_images)):.3f}.\"\n",
    "        )\n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 784)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key idea is to train on batch and update the weights then. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_0:(500, 784),w01(784, 40), layer_1:(500, 40)\n",
      "layer_0:(500, 784),w01(784, 40), layer_1:(500, 40)\n"
     ]
    }
   ],
   "source": [
    "alpha, iterations, hidden_size, pixels_per_image, num_labels = (0.001, 1, 40, 28*28, 10)\n",
    "batch_size = 500\n",
    "\n",
    "weights_0_1 = 0.2*np.random.random((pixels_per_image,hidden_size)) - 0.1\n",
    "weights_1_2 = 0.2*np.random.random((hidden_size,num_labels)) - 0.1\n",
    "\n",
    "for j in range(iterations):\n",
    "    error, correct_cnt = (0.0, 0)\n",
    "    \n",
    "    #################################################\n",
    "    for i in range(int(len(trn_images) / batch_size)):\n",
    "        batch_start, batch_end = ((i * batch_size),((i+1)*batch_size))\n",
    "    \n",
    "        layer_0 = trn_images[batch_start:batch_end]\n",
    "        layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "        \n",
    "        print(f\"layer_0:{layer_0.shape},w01{weights_0_1.shape}, layer_1:{layer_1.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Alterations\n",
    "\n",
    "- batch size 100 introduced. \n",
    "- hidden size increased from 40 to 100\n",
    "- alpha reduced from 0.005 to 0.001\n",
    "- iterations reduced from 350 to 300 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:0, Trn-Err:.1.272, Tst-Err:.0.816, Trn-Acc:0.161, Tst-Acc:0.383.\n",
      "Iteration:10, Trn-Err:.0.592, Tst-Err:.0.569, Trn-Acc:0.672, Tst-Acc:0.718.\n",
      "Iteration:20, Trn-Err:.0.530, Tst-Err:.0.509, Trn-Acc:0.727, Tst-Acc:0.758.\n",
      "Iteration:30, Trn-Err:.0.498, Tst-Err:.0.483, Trn-Acc:0.758, Tst-Acc:0.781.\n",
      "Iteration:40, Trn-Err:.0.486, Tst-Err:.0.464, Trn-Acc:0.750, Tst-Acc:0.791.\n",
      "Iteration:50, Trn-Err:.0.463, Tst-Err:.0.453, Trn-Acc:0.784, Tst-Acc:0.798.\n",
      "Iteration:60, Trn-Err:.0.446, Tst-Err:.0.446, Trn-Acc:0.801, Tst-Acc:0.801.\n",
      "Iteration:70, Trn-Err:.0.444, Tst-Err:.0.438, Trn-Acc:0.807, Tst-Acc:0.805.\n",
      "Iteration:80, Trn-Err:.0.450, Tst-Err:.0.440, Trn-Acc:0.803, Tst-Acc:0.807.\n",
      "Iteration:90, Trn-Err:.0.444, Tst-Err:.0.437, Trn-Acc:0.798, Tst-Acc:0.806.\n",
      "Iteration:100, Trn-Err:.0.436, Tst-Err:.0.437, Trn-Acc:0.805, Tst-Acc:0.803.\n",
      "Iteration:110, Trn-Err:.0.421, Tst-Err:.0.431, Trn-Acc:0.818, Tst-Acc:0.802.\n",
      "Iteration:120, Trn-Err:.0.419, Tst-Err:.0.434, Trn-Acc:0.824, Tst-Acc:0.801.\n",
      "Iteration:130, Trn-Err:.0.424, Tst-Err:.0.432, Trn-Acc:0.826, Tst-Acc:0.800.\n",
      "Iteration:140, Trn-Err:.0.430, Tst-Err:.0.441, Trn-Acc:0.832, Tst-Acc:0.800.\n",
      "Iteration:150, Trn-Err:.0.411, Tst-Err:.0.438, Trn-Acc:0.818, Tst-Acc:0.797.\n",
      "Iteration:160, Trn-Err:.0.423, Tst-Err:.0.435, Trn-Acc:0.811, Tst-Acc:0.805.\n",
      "Iteration:170, Trn-Err:.0.413, Tst-Err:.0.437, Trn-Acc:0.846, Tst-Acc:0.795.\n",
      "Iteration:180, Trn-Err:.0.406, Tst-Err:.0.432, Trn-Acc:0.842, Tst-Acc:0.805.\n",
      "Iteration:190, Trn-Err:.0.405, Tst-Err:.0.430, Trn-Acc:0.840, Tst-Acc:0.801.\n",
      "Iteration:200, Trn-Err:.0.416, Tst-Err:.0.430, Trn-Acc:0.844, Tst-Acc:0.809.\n",
      "Iteration:210, Trn-Err:.0.399, Tst-Err:.0.428, Trn-Acc:0.844, Tst-Acc:0.801.\n",
      "Iteration:220, Trn-Err:.0.392, Tst-Err:.0.427, Trn-Acc:0.841, Tst-Acc:0.806.\n",
      "Iteration:230, Trn-Err:.0.390, Tst-Err:.0.425, Trn-Acc:0.849, Tst-Acc:0.809.\n",
      "Iteration:240, Trn-Err:.0.393, Tst-Err:.0.425, Trn-Acc:0.850, Tst-Acc:0.811.\n",
      "Iteration:250, Trn-Err:.0.385, Tst-Err:.0.425, Trn-Acc:0.851, Tst-Acc:0.807.\n",
      "Iteration:260, Trn-Err:.0.391, Tst-Err:.0.424, Trn-Acc:0.853, Tst-Acc:0.813.\n",
      "Iteration:270, Trn-Err:.0.378, Tst-Err:.0.422, Trn-Acc:0.866, Tst-Acc:0.807.\n",
      "Iteration:280, Trn-Err:.0.393, Tst-Err:.0.421, Trn-Acc:0.856, Tst-Acc:0.812.\n",
      "Iteration:290, Trn-Err:.0.376, Tst-Err:.0.418, Trn-Acc:0.862, Tst-Acc:0.806.\n",
      "Iteration:299, Trn-Err:.0.380, Tst-Err:.0.418, Trn-Acc:0.852, Tst-Acc:0.812.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "alpha, iterations, hidden_size, pixels_per_image, num_labels = (0.001, 300, 100, 28*28, 10)\n",
    "batch_size = 100\n",
    "\n",
    "weights_0_1 = 0.2*np.random.random((pixels_per_image,hidden_size)) - 0.1\n",
    "weights_1_2 = 0.2*np.random.random((hidden_size,num_labels)) - 0.1\n",
    "\n",
    "for j in range(iterations):\n",
    "    error, correct_cnt = (0.0, 0)\n",
    "    \n",
    "    #################################################\n",
    "    for i in range(int(len(trn_images) / batch_size)):\n",
    "        batch_start, batch_end = ((i * batch_size),((i+1)*batch_size))\n",
    "        \n",
    "        layer_0 = trn_images[batch_start:batch_end]\n",
    "        ###########################################\n",
    "        \n",
    "        layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "        dropout_mask = np.random.randint(2,size=layer_1.shape)\n",
    "        layer_1 *= dropout_mask * 2\n",
    "        \n",
    "        layer_2 = np.dot(layer_1,weights_1_2)\n",
    "\n",
    "        error += np.sum((trn_labels[batch_start:batch_end] - layer_2) ** 2)\n",
    "        \n",
    "        layer_2_delta = (trn_labels[batch_start:batch_end]-layer_2)\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T)* relu2deriv(layer_1)\n",
    "        layer_1_delta *= dropout_mask\n",
    "\n",
    "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
    "        weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
    "        \n",
    "        \n",
    "        #••••••••••••••••••••••••••••••••••••••••••••••\n",
    "        for k in range(batch_size):\n",
    "            correct_cnt += int(np.argmax(layer_2[k:k+1]) == np.argmax(trn_labels[batch_start+k:batch_start+k+1]))\n",
    "        #**********************************************\n",
    "        \n",
    "    if(j % 10 == 0 or j == iterations-1):\n",
    "        tst_error, tst_correct_cnt = (0.0, 0)\n",
    "\n",
    "        for i in range(len(tst_images)):\n",
    "\n",
    "            layer_0 = tst_images[i:i+1]\n",
    "            layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "            layer_2 = np.dot(layer_1,weights_1_2)\n",
    "\n",
    "            tst_error += np.sum((tst_labels[i:i+1] - layer_2) ** 2)\n",
    "            tst_correct_cnt += int(np.argmax(layer_2) == np.argmax(tst_labels[i:i+1]))\n",
    "            \n",
    "        msg = (\n",
    "            f\"Iteration:{j}, \"\n",
    "            f\"Trn-Err:.{error/len(trn_images):.3f}, \"\n",
    "            f\"Tst-Err:.{tst_error/len(tst_images):.3f}, \"\n",
    "            f\"Trn-Acc:{correct_cnt/float(len(trn_images)):.3f}, \"\n",
    "            f\"Tst-Acc:{tst_correct_cnt/float(len(tst_images)):.3f}.\"\n",
    "        )\n",
    "        print(msg)\n",
    "        \n",
    "        \n",
    "\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
